{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmEjIFl/CenLqmN1GSawqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prosenjit220901/Machine-Learning/blob/main/NLP_In_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsAV2ZUsd_Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892f122f-b020-49a5-f297-7ab7169c5de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYcHc-0GGL2",
        "outputId": "e674d6cb-ae28-4122-e1d3-fc4c365d8a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\"Hello, I am Prosenjit. I am an undergraduate student of Electronics and Communication Enginnering Discipline. Now i am learning NLP in Machine Learning from different sources like youtube,website etc.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4QLYnnQ6CyPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1eshkuoD-Sy",
        "outputId": "4c0f850c-81a2-49e4-8a48-62cb1d3795ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Prosenjit. I am an undergraduate student of Electronics and Communication Enginnering Discipline. Now i am learning NLP in Machine Learning from different sources like youtube,website etc. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenaization\n",
        "#Sentence--->Paragraphs\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "dCk1OzRHEUoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=sent_tokenize(corpus)\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gMT1PENFYKm",
        "outputId": "a6ac36c4-4529-45bd-9267-5d7d56cfe362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello, I am Prosenjit.', 'I am an undergraduate student of Electronics and Communication Enginnering Discipline.', 'Now i am learning NLP in Machine Learning from different sources like youtube,website etc.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj0cgS3TG46E",
        "outputId": "b6db9de9-8e9e-4271-88d7-0fb9ceb7add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentence:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaOVbChwHOYU",
        "outputId": "04f954f8-d72f-4f6a-87d4-b74b4f4d20e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Prosenjit.\n",
            "I am an undergraduate student of Electronics and Communication Enginnering Discipline.\n",
            "Now i am learning NLP in Machine Learning from different sources like youtube,website etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenaization\n",
        "## Paragraph-->words\n",
        "## Sentence--->words\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "VhE3kHKiHWDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktqsSD-2H-dv",
        "outputId": "b1f7a752-35a8-4ff6-e20a-09b5ed260daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'Prosenjit',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'an',\n",
              " 'undergraduate',\n",
              " 'student',\n",
              " 'of',\n",
              " 'Electronics',\n",
              " 'and',\n",
              " 'Communication',\n",
              " 'Enginnering',\n",
              " 'Discipline',\n",
              " '.',\n",
              " 'Now',\n",
              " 'i',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'NLP',\n",
              " 'in',\n",
              " 'Machine',\n",
              " 'Learning',\n",
              " 'from',\n",
              " 'different',\n",
              " 'sources',\n",
              " 'like',\n",
              " 'youtube',\n",
              " ',',\n",
              " 'website',\n",
              " 'etc',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_tokenize(corpus):\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMyvyvirIEfZ",
        "outputId": "05edbbc2-36fd-4b61-9dfb-b03dc5ccf853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            ",\n",
            "I\n",
            "am\n",
            "Prosenjit\n",
            ".\n",
            "I\n",
            "am\n",
            "an\n",
            "undergraduate\n",
            "student\n",
            "of\n",
            "Electronics\n",
            "and\n",
            "Communication\n",
            "Enginnering\n",
            "Discipline\n",
            ".\n",
            "Now\n",
            "i\n",
            "am\n",
            "learning\n",
            "NLP\n",
            "in\n",
            "Machine\n",
            "Learning\n",
            "from\n",
            "different\n",
            "sources\n",
            "like\n",
            "youtube\n",
            ",\n",
            "website\n",
            "etc\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentence:\n",
        "  print(word_tokenize(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5s1WTT5IgLz",
        "outputId": "9144fb39-1431-4430-d154-8f8275256010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'I', 'am', 'Prosenjit', '.']\n",
            "['I', 'am', 'an', 'undergraduate', 'student', 'of', 'Electronics', 'and', 'Communication', 'Enginnering', 'Discipline', '.']\n",
            "['Now', 'i', 'am', 'learning', 'NLP', 'in', 'Machine', 'Learning', 'from', 'different', 'sources', 'like', 'youtube', ',', 'website', 'etc', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "zQnnaBpWJQJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=TreebankWordTokenizer()"
      ],
      "metadata": {
        "id": "V0wt5sUgJYO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjsDL60RJc8k",
        "outputId": "7cb962fc-c736-4137-e318-37d78f0aac62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'Prosenjit.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'an',\n",
              " 'undergraduate',\n",
              " 'student',\n",
              " 'of',\n",
              " 'Electronics',\n",
              " 'and',\n",
              " 'Communication',\n",
              " 'Enginnering',\n",
              " 'Discipline.',\n",
              " 'Now',\n",
              " 'i',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'NLP',\n",
              " 'in',\n",
              " 'Machine',\n",
              " 'Learning',\n",
              " 'from',\n",
              " 'different',\n",
              " 'sources',\n",
              " 'like',\n",
              " 'youtube',\n",
              " ',',\n",
              " 'website',\n",
              " 'etc',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**\n",
        "\n",
        "Stemming is the process of reducing a word to its stem that affixes to suffixes and prefixes or to the roots of words known as \"lemmas\"."
      ],
      "metadata": {
        "id": "4BFMHdM_Kqjk"
      }
    }
  ]
}